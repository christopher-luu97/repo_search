{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: github.com/bebrws/openai-search-codebase-and-chat-about-it\n",
    "\n",
    "import os\n",
    "import glob \n",
    "from tree_sitter import Language, Parser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All File Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "dlsym(0x96707220, tree_sitter_javascript): symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m PY_LANGUAGE \u001b[39m=\u001b[39m (Language(\u001b[39m'\u001b[39m\u001b[39mbuild/my-languages.so\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m*.py\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# TS_LANGUAGE = (Language('build/my-languages.so', 'typescript'), \"*.ts\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# TSX_LANGUAGE = (Language('build/my-languages.so', 'typescript'), \"*.tsx\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# CSS_LANGUAGE = (Language('build/my-languages.so', \"css\"), \"*.css\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# HTML_LANGUAGE = (Language('build/my-languages.so', \"html\"), \"*.html\")\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m JS_LANGUAGE \u001b[39m=\u001b[39m (Language(\u001b[39m'\u001b[39;49m\u001b[39mbuild/my-languages.so\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mjavascript\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39m*.js\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m JSON_LANGUAGE \u001b[39m=\u001b[39m (Language(\u001b[39m'\u001b[39m\u001b[39mbuild/my-languages.so\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m*.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m DOCKER_LANGUAGE \u001b[39m=\u001b[39m (Language(\u001b[39m'\u001b[39m\u001b[39mbuild/my-languages.so\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdockerfile\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m*.dockerfile\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/tree_sitter/__init__.py:83\u001b[0m, in \u001b[0;36mLanguage.__init__\u001b[0;34m(self, library_path, name)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m name\n\u001b[1;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlib \u001b[39m=\u001b[39m cdll\u001b[39m.\u001b[39mLoadLibrary(library_path)\n\u001b[0;32m---> 83\u001b[0m language_function \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlib, \u001b[39m\"\u001b[39;49m\u001b[39mtree_sitter_\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m name)\n\u001b[1;32m     84\u001b[0m language_function\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m c_void_p\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage_id \u001b[39m=\u001b[39m language_function()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ctypes/__init__.py:387\u001b[0m, in \u001b[0;36mCDLL.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mif\u001b[39;00m name\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 387\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(name)\n\u001b[1;32m    388\u001b[0m \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, name, func)\n\u001b[1;32m    389\u001b[0m \u001b[39mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ctypes/__init__.py:392\u001b[0m, in \u001b[0;36mCDLL.__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name_or_ordinal):\n\u001b[0;32m--> 392\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_FuncPtr((name_or_ordinal, \u001b[39mself\u001b[39;49m))\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(name_or_ordinal, \u001b[39mint\u001b[39m):\n\u001b[1;32m    394\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m name_or_ordinal\n",
      "\u001b[0;31mAttributeError\u001b[0m: dlsym(0x96707220, tree_sitter_javascript): symbol not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "PY_LANGUAGE = (Language('build/my-languages.so', 'python'), \"*.py\")\n",
    "# TS_LANGUAGE = (Language('build/my-languages.so', 'typescript'), \"*.ts\")\n",
    "# TSX_LANGUAGE = (Language('build/my-languages.so', 'typescript'), \"*.tsx\")\n",
    "# CSS_LANGUAGE = (Language('build/my-languages.so', \"css\"), \"*.css\")\n",
    "# HTML_LANGUAGE = (Language('build/my-languages.so', \"html\"), \"*.html\")\n",
    "JS_LANGUAGE = (Language('build/my-languages.so', 'javascript'), \"*.js\")\n",
    "# JSON_LANGUAGE = (Language('build/my-languages.so', 'json'), \"*.json\")\n",
    "# DOCKER_LANGUAGE = (Language('build/my-languages.so', 'dockerfile'), \"*.dockerfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_language = PY_LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_functions(filepath: str):\n",
    "    \"\"\"\n",
    "    Get all the functions in a Python File\n",
    "\n",
    "    Args:\n",
    "        filepath (str): _description_\n",
    "    \"\"\"\n",
    "    codestr = open(filepath).read().replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    parser = Parser()\n",
    "    parser.set_language(current_language[0])\n",
    "\n",
    "    tree = parser.parse(bytes(codestr, \"utf8\"))\n",
    "    cursor = tree.walk()\n",
    "    cursor.goto_first_child()\n",
    "\n",
    "    while True:\n",
    "        print(\"type: \", cursor.node.type)\n",
    "        print(\"bye locations: \", cursor.node.start_byte,\n",
    "              \" - \", cursor.node.end_byte)\n",
    "        code = codestr[cursor.node.start_byte:cursor.node.end_byte]\n",
    "        node_type = cursor.node.type\n",
    "        print(\"code:\\n\", code)\n",
    "        code_filename = {\n",
    "            \"code\": code, \"node_type\": node_type, \"filepath\": filepath\n",
    "        }\n",
    "        if code.strip() != \"\":\n",
    "            print(\"code_filename: \", code_filename)\n",
    "            yield code_filename\n",
    "        \n",
    "        has_sibling = cursor.goto_next_sibling()\n",
    "        if not has_sibling:\n",
    "            break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Only Tree-Sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PY_LANGUAGE = (Language('build/my-languages.so', 'python'), \"*.py\")\n",
    "\n",
    "current_language = PY_LANGUAGE\n",
    "\n",
    "def get_functions(filepath: str):\n",
    "    \"\"\"\n",
    "    Get all the functions in a Python File\n",
    "\n",
    "    Args:\n",
    "        filepath (str): _description_\n",
    "    \"\"\"\n",
    "    codestr = open(filepath).read().replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    parser = Parser()\n",
    "    parser.set_language(current_language[0])\n",
    "\n",
    "    tree = parser.parse(bytes(codestr, \"utf8\"))\n",
    "    cursor = tree.walk()\n",
    "    cursor.goto_first_child()\n",
    "\n",
    "    while True:\n",
    "        print(\"type: \", cursor.node.type)\n",
    "        print(\"bye locations: \", cursor.node.start_byte,\n",
    "              \" - \", cursor.node.end_byte)\n",
    "        code = codestr[cursor.node.start_byte:cursor.node.end_byte]\n",
    "        node_type = cursor.node.type\n",
    "        print(\"code:\\n\", code)\n",
    "        code_filename = {\n",
    "            \"code\": code, \"node_type\": node_type, \"filepath\": filepath\n",
    "        }\n",
    "        if code.strip() != \"\":\n",
    "            print(\"code_filename: \", code_filename)\n",
    "            yield code_filename\n",
    "        \n",
    "        has_sibling = cursor.goto_next_sibling()\n",
    "        if not has_sibling:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_root = \"./search_app/transcription\"#input(\"Full path to code directory to search/embed/query: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./search_app/transcription', [], ['transcription_requirements.txt', 'download.py', '__init__.py', 'README.md', 'transcribe.py', 'main.py']) <class 'tuple'> ./search_app/transcription\n"
     ]
    }
   ],
   "source": [
    "for x in os.walk(code_root):\n",
    "    print(x,type(x), x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*.py\n"
     ]
    }
   ],
   "source": [
    "print(current_language[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tree_sitter.Language at 0x107b8b370>, '*.py')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./search_app/transcription/download.py',\n",
       " './search_app/transcription/__init__.py',\n",
       " './search_app/transcription/transcribe.py',\n",
       " './search_app/transcription/main.py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(os.path.join(x[0], current_language[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of files found:  4\n"
     ]
    }
   ],
   "source": [
    "code_files = [y for x in os.walk(code_root)\n",
    "              for y in glob.glob(os.path.join(x[0], current_language[1]))]\n",
    "\n",
    "print(\"\\nTotal number of files found: \", len(code_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./search_app/transcription/download.py',\n",
       " './search_app/transcription/__init__.py',\n",
       " './search_app/transcription/transcribe.py',\n",
       " './search_app/transcription/main.py']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  import_from_statement\n",
      "bye locations:  0  -  28\n",
      "code:\n",
      " from yt_dlp import YoutubeDL\n",
      "code_filename:  {'code': 'from yt_dlp import YoutubeDL', 'node_type': 'import_from_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  import_statement\n",
      "bye locations:  29  -  42\n",
      "code:\n",
      " import pytube\n",
      "code_filename:  {'code': 'import pytube', 'node_type': 'import_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  import_from_statement\n",
      "bye locations:  43  -  72\n",
      "code:\n",
      " from typing import List, Dict\n",
      "code_filename:  {'code': 'from typing import List, Dict', 'node_type': 'import_from_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  import_statement\n",
      "bye locations:  73  -  82\n",
      "code:\n",
      " import os\n",
      "code_filename:  {'code': 'import os', 'node_type': 'import_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  import_statement\n",
      "bye locations:  83  -  92\n",
      "code:\n",
      " import re\n",
      "code_filename:  {'code': 'import re', 'node_type': 'import_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  import_statement\n",
      "bye locations:  93  -  108\n",
      "code:\n",
      " import requests\n",
      "code_filename:  {'code': 'import requests', 'node_type': 'import_statement', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  function_definition\n",
      "bye locations:  110  -  1025\n",
      "code:\n",
      " def get_yt_data(url_link:str) -> List[Dict]:\n",
      "  \"\"\"\n",
      "  Given a link, generate the data for each link and yt video\n",
      "\n",
      "  ARGS:\n",
      "    url_link(str): the url link to a video or playlist\n",
      "\n",
      "  Returns:\n",
      "    video_urls(List[Dict]): List of dictionary objects that contain basic metadata on the YT video\n",
      "\n",
      "  \"\"\"\n",
      "  video_urls = []\n",
      "  if \"playlist\" in url_link: # playlists\n",
      "    playlist = pytube.Playlist(url_link)\n",
      "    print('Number Of Videos In playlist: %s' % len(playlist.video_urls))\n",
      "    for url in playlist:\n",
      "        data_object = {\"title\":pytube.YouTube(url).title,\n",
      "                      \"description\":pytube.YouTube(url).description,\n",
      "                       \"url\":url}\n",
      "        video_urls.append(data_object)\n",
      "    else:\n",
      "      data_object = {\"title\":pytube.YouTube(url).title,\n",
      "                      \"description\":pytube.YouTube(url).description,\n",
      "                     \"url\":url}\n",
      "      video_urls.append(data_object)\n",
      "  return video_urls\n",
      "code_filename:  {'code': 'def get_yt_data(url_link:str) -> List[Dict]:\\n  \"\"\"\\n  Given a link, generate the data for each link and yt video\\n\\n  ARGS:\\n    url_link(str): the url link to a video or playlist\\n\\n  Returns:\\n    video_urls(List[Dict]): List of dictionary objects that contain basic metadata on the YT video\\n\\n  \"\"\"\\n  video_urls = []\\n  if \"playlist\" in url_link: # playlists\\n    playlist = pytube.Playlist(url_link)\\n    print(\\'Number Of Videos In playlist: %s\\' % len(playlist.video_urls))\\n    for url in playlist:\\n        data_object = {\"title\":pytube.YouTube(url).title,\\n                      \"description\":pytube.YouTube(url).description,\\n                       \"url\":url}\\n        video_urls.append(data_object)\\n    else:\\n      data_object = {\"title\":pytube.YouTube(url).title,\\n                      \"description\":pytube.YouTube(url).description,\\n                     \"url\":url}\\n      video_urls.append(data_object)\\n  return video_urls', 'node_type': 'function_definition', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  function_definition\n",
      "bye locations:  1027  -  1389\n",
      "code:\n",
      " def download_yt_playlist(video_urls:list, path:str):\n",
      "  \"\"\"\n",
      "  Download yt videos from list of links\n",
      "\n",
      "  ARGS:\n",
      "    video_urls(list): A list containing a hsot of youtube URL links\n",
      "    path (str): path to save files\n",
      "\n",
      "  \"\"\"\n",
      "  for item in video_urls:\n",
      "    download_yt(item[\"url\"], item[\"title\"], path)\n",
      "    item[\"file_location\"] = os.path.join(path, item[\"title\"]+\".mp3\")\n",
      "code_filename:  {'code': 'def download_yt_playlist(video_urls:list, path:str):\\n  \"\"\"\\n  Download yt videos from list of links\\n\\n  ARGS:\\n    video_urls(list): A list containing a hsot of youtube URL links\\n    path (str): path to save files\\n\\n  \"\"\"\\n  for item in video_urls:\\n    download_yt(item[\"url\"], item[\"title\"], path)\\n    item[\"file_location\"] = os.path.join(path, item[\"title\"]+\".mp3\")', 'node_type': 'function_definition', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  function_definition\n",
      "bye locations:  1391  -  2131\n",
      "code:\n",
      " def download_yt(url:str, out_fname:str, path:str = \"input\"):\n",
      "  \"\"\"\n",
      "  Download YT videos to a specific location\n",
      "\n",
      "  ARGS:\n",
      "    url(str): A youtube url to a video\n",
      "    out_fname(str): The output file name\n",
      "    path(str): A path to save the file to.\n",
      "  \"\"\"\n",
      "  if not os.path.exists(path):\n",
      "    print(\"Path does not exist\")\n",
      "    return\n",
      "  output = os.path.join(path, out_fname) # example: path == \"input\"\n",
      "  ydl_opts = {\n",
      "      \"format\": \"bestaudio/best\",\n",
      "      \"postprocessors\": [\n",
      "          {\n",
      "              \"key\": \"FFmpegExtractAudio\",\n",
      "              \"preferredcodec\": \"mp3\",\n",
      "              \"preferredquality\": \"192\",\n",
      "          }\n",
      "      ],\n",
      "      \"fragment_retries\": 10,\n",
      "      \"outtmpl\": output,\n",
      "  }\n",
      "  with YoutubeDL(ydl_opts) as ydl:\n",
      "    ydl.download([url])\n",
      "code_filename:  {'code': 'def download_yt(url:str, out_fname:str, path:str = \"input\"):\\n  \"\"\"\\n  Download YT videos to a specific location\\n\\n  ARGS:\\n    url(str): A youtube url to a video\\n    out_fname(str): The output file name\\n    path(str): A path to save the file to.\\n  \"\"\"\\n  if not os.path.exists(path):\\n    print(\"Path does not exist\")\\n    return\\n  output = os.path.join(path, out_fname) # example: path == \"input\"\\n  ydl_opts = {\\n      \"format\": \"bestaudio/best\",\\n      \"postprocessors\": [\\n          {\\n              \"key\": \"FFmpegExtractAudio\",\\n              \"preferredcodec\": \"mp3\",\\n              \"preferredquality\": \"192\",\\n          }\\n      ],\\n      \"fragment_retries\": 10,\\n      \"outtmpl\": output,\\n  }\\n  with YoutubeDL(ydl_opts) as ydl:\\n    ydl.download([url])', 'node_type': 'function_definition', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  function_definition\n",
      "bye locations:  2135  -  2758\n",
      "code:\n",
      " def get_yt_thumbnail_link(url_list:List[Dict]):\n",
      "    \"\"\"\n",
      "    Download the youtube thumbnails as jpg\n",
      "\n",
      "    Args:\n",
      "        url_list (List[Dict[str]]): List of youtube video URLS contained in dictionaries\n",
      "    \"\"\"\n",
      "    pattern = \"watch\\?v=(.+)\" # e.g. 'https://www.youtube.com/watch?v=Z56Jmr9Z34Q'-> 'Z56Jmr9Z34Q'\n",
      "    for item in url_list:\n",
      "      url = item['url']\n",
      "      matched_pattern = re.search(pattern, url)\n",
      "      if matched_pattern:\n",
      "          content = matched_pattern.group(1)\n",
      "          item['thumbnail'] = \"https://i.ytimg.com/vi/\" + content +\"/maxresdefault.jpg\" # location of where yt stores thumbnails\n",
      "    return url_list\n",
      "code_filename:  {'code': 'def get_yt_thumbnail_link(url_list:List[Dict]):\\n    \"\"\"\\n    Download the youtube thumbnails as jpg\\n\\n    Args:\\n        url_list (List[Dict[str]]): List of youtube video URLS contained in dictionaries\\n    \"\"\"\\n    pattern = \"watch\\\\?v=(.+)\" # e.g. \\'https://www.youtube.com/watch?v=Z56Jmr9Z34Q\\'-> \\'Z56Jmr9Z34Q\\'\\n    for item in url_list:\\n      url = item[\\'url\\']\\n      matched_pattern = re.search(pattern, url)\\n      if matched_pattern:\\n          content = matched_pattern.group(1)\\n          item[\\'thumbnail\\'] = \"https://i.ytimg.com/vi/\" + content +\"/maxresdefault.jpg\" # location of where yt stores thumbnails\\n    return url_list', 'node_type': 'function_definition', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  function_definition\n",
      "bye locations:  2760  -  3177\n",
      "code:\n",
      " def download_yt_thumbnail(url_list:List[Dict], path:str):\n",
      "  \"\"\"\n",
      "  Downloads youtube thumbnails to a path\n",
      "\n",
      "  Args:\n",
      "      url_list (List[Dict[str]]): List of youtube data objects\n",
      "      path (str): Path to save youtube thumbnails\n",
      "  \"\"\"\n",
      "  for item in url_list:\n",
      "    img_data = requests.get(item['thumbnail']).content\n",
      "    with open(os.path.join(path, item['title']+'.jpg'), 'wb') as handler:\n",
      "        handler.write(img_data)\n",
      "code_filename:  {'code': 'def download_yt_thumbnail(url_list:List[Dict], path:str):\\n  \"\"\"\\n  Downloads youtube thumbnails to a path\\n\\n  Args:\\n      url_list (List[Dict[str]]): List of youtube data objects\\n      path (str): Path to save youtube thumbnails\\n  \"\"\"\\n  for item in url_list:\\n    img_data = requests.get(item[\\'thumbnail\\']).content\\n    with open(os.path.join(path, item[\\'title\\']+\\'.jpg\\'), \\'wb\\') as handler:\\n        handler.write(img_data)', 'node_type': 'function_definition', 'filepath': './search_app/transcription/download.py'}\n",
      "type:  module\n",
      "bye locations:  0  -  0\n",
      "code:\n",
      " \n",
      "type:  import_statement\n",
      "bye locations:  0  -  15\n",
      "code:\n",
      " import whisperx\n",
      "code_filename:  {'code': 'import whisperx', 'node_type': 'import_statement', 'filepath': './search_app/transcription/transcribe.py'}\n",
      "type:  import_statement\n",
      "bye locations:  16  -  28\n",
      "code:\n",
      " import torch\n",
      "code_filename:  {'code': 'import torch', 'node_type': 'import_statement', 'filepath': './search_app/transcription/transcribe.py'}\n",
      "type:  class_definition\n",
      "bye locations:  30  -  2589\n",
      "code:\n",
      " class Transcriber():\n",
      "    def __init__(self, device:str = \"cpu\", batch_size:int=4, compute_type:str=\"int8\"):\n",
      "        \"\"\"\n",
      "        Instantiate the class with minimal resources\n",
      "\n",
      "        Args:\n",
      "            device (str, optional): cpu or cuda. Defaults to \"cpu\".\n",
      "            batch_size (int, optional): Bigger number requires more memory. Defaults to 4.\n",
      "            compute_type (str, optional): float16 requires more memory. Defaults to \"int8\".\n",
      "        \"\"\"\n",
      "        self.device = device\n",
      "        self.batch_size = batch_size\n",
      "        self.compute_type = compute_type\n",
      "\n",
      "    def transcribe_file(self, audio_file:str, title:str) -> list:\n",
      "        \"\"\"\n",
      "        Transcripe the files\n",
      "\n",
      "        Args:\n",
      "            audio_file (str): Name of the audio file\n",
      "            title (str): title of the video\n",
      "\n",
      "        Returns:\n",
      "            list: _description_\n",
      "        \"\"\"\n",
      "        device = self.device\n",
      "        compute_type = self.compute_type\n",
      "        batch_size = self.batch_size\n",
      "\n",
      "        # 1. Transcribe with original whisper (batched) with medium.en for speed/accuracy tradeoff\n",
      "        model = whisperx.load_model(\"medium.en\", device, compute_type=compute_type)\n",
      "\n",
      "        audio = whisperx.load_audio(audio_file)\n",
      "        result = model.transcribe(audio, batch_size=batch_size)\n",
      "\n",
      "        # delete model if low on GPU resources\n",
      "        # import gc; gc.collect(); torch.cuda.empty_cache(); del model\n",
      "\n",
      "        # 2. Align whisper output\n",
      "        model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
      "        result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
      "        import gc; gc.collect(); torch.cuda.empty_cache(); del model\n",
      "        counter = 0\n",
      "        for r in result[\"segments\"]:\n",
      "            r['id'] = str(counter)+\"_\"+title\n",
      "            r['title'] = title\n",
      "            counter +=1\n",
      "\n",
      "        return result\n",
      "\n",
      "    def process_data(self, data:dict)->dict:\n",
      "        \"\"\"\n",
      "        Process the data to a specific output format\n",
      "\n",
      "        Args:\n",
      "            data (dict): Dictionary of transcription results\n",
      "\n",
      "        Returns:\n",
      "            output (dict): Dictionary with new schema\n",
      "        \"\"\"\n",
      "        # Extract the necessary information from the data\n",
      "        title = data['title']\n",
      "        url = data['file_location']\n",
      "\n",
      "        # Call the transcribe_file function with the video URL\n",
      "        result = self.transcribe_file(url, title)\n",
      "\n",
      "        # Create a dictionary with the desired output format\n",
      "        output = {\n",
      "            'title': title,\n",
      "            'segments': result[\"segments\"]\n",
      "        }\n",
      "\n",
      "        return output\n",
      "code_filename:  {'code': 'class Transcriber():\\n    def __init__(self, device:str = \"cpu\", batch_size:int=4, compute_type:str=\"int8\"):\\n        \"\"\"\\n        Instantiate the class with minimal resources\\n\\n        Args:\\n            device (str, optional): cpu or cuda. Defaults to \"cpu\".\\n            batch_size (int, optional): Bigger number requires more memory. Defaults to 4.\\n            compute_type (str, optional): float16 requires more memory. Defaults to \"int8\".\\n        \"\"\"\\n        self.device = device\\n        self.batch_size = batch_size\\n        self.compute_type = compute_type\\n\\n    def transcribe_file(self, audio_file:str, title:str) -> list:\\n        \"\"\"\\n        Transcripe the files\\n\\n        Args:\\n            audio_file (str): Name of the audio file\\n            title (str): title of the video\\n\\n        Returns:\\n            list: _description_\\n        \"\"\"\\n        device = self.device\\n        compute_type = self.compute_type\\n        batch_size = self.batch_size\\n\\n        # 1. Transcribe with original whisper (batched) with medium.en for speed/accuracy tradeoff\\n        model = whisperx.load_model(\"medium.en\", device, compute_type=compute_type)\\n\\n        audio = whisperx.load_audio(audio_file)\\n        result = model.transcribe(audio, batch_size=batch_size)\\n\\n        # delete model if low on GPU resources\\n        # import gc; gc.collect(); torch.cuda.empty_cache(); del model\\n\\n        # 2. Align whisper output\\n        model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\\n        result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\\n        import gc; gc.collect(); torch.cuda.empty_cache(); del model\\n        counter = 0\\n        for r in result[\"segments\"]:\\n            r[\\'id\\'] = str(counter)+\"_\"+title\\n            r[\\'title\\'] = title\\n            counter +=1\\n\\n        return result\\n\\n    def process_data(self, data:dict)->dict:\\n        \"\"\"\\n        Process the data to a specific output format\\n\\n        Args:\\n            data (dict): Dictionary of transcription results\\n\\n        Returns:\\n            output (dict): Dictionary with new schema\\n        \"\"\"\\n        # Extract the necessary information from the data\\n        title = data[\\'title\\']\\n        url = data[\\'file_location\\']\\n\\n        # Call the transcribe_file function with the video URL\\n        result = self.transcribe_file(url, title)\\n\\n        # Create a dictionary with the desired output format\\n        output = {\\n            \\'title\\': title,\\n            \\'segments\\': result[\"segments\"]\\n        }\\n\\n        return output', 'node_type': 'class_definition', 'filepath': './search_app/transcription/transcribe.py'}\n",
      "type:  import_statement\n",
      "bye locations:  0  -  9\n",
      "code:\n",
      " import os\n",
      "code_filename:  {'code': 'import os', 'node_type': 'import_statement', 'filepath': './search_app/transcription/main.py'}\n",
      "type:  import_statement\n",
      "bye locations:  10  -  21\n",
      "code:\n",
      " import json\n",
      "code_filename:  {'code': 'import json', 'node_type': 'import_statement', 'filepath': './search_app/transcription/main.py'}\n",
      "type:  import_from_statement\n",
      "bye locations:  23  -  45\n",
      "code:\n",
      " from download import *\n",
      "code_filename:  {'code': 'from download import *', 'node_type': 'import_from_statement', 'filepath': './search_app/transcription/main.py'}\n",
      "type:  import_from_statement\n",
      "bye locations:  46  -  80\n",
      "code:\n",
      " from transcribe import Transcriber\n",
      "code_filename:  {'code': 'from transcribe import Transcriber', 'node_type': 'import_from_statement', 'filepath': './search_app/transcription/main.py'}\n",
      "type:  function_definition\n",
      "bye locations:  82  -  774\n",
      "code:\n",
      " def main(folder_path:str, transcriber: object):\n",
      "    \"\"\"\n",
      "    Transcribe a list of files\n",
      "\n",
      "    Args:\n",
      "        folder_path (str): folder path to where the downloaded videos are\n",
      "        transcriber (object): take in the transcriber object\n",
      "    \"\"\"\n",
      "    file_paths = []\n",
      "    for data in os.listdir(folder_path):\n",
      "        data_ob = {\"title\":data[:-4], \"file_location\":os.path.join(folder_path,data)}\n",
      "        file_paths.append(data_ob)\n",
      "\n",
      "    for item in file_paths:\n",
      "        if \".mp3\" in item['file_location']: # Basic check for now.\n",
      "            result = transcriber.process_data(item)\n",
      "            with open(os.path.join(folder_path, item['title']+\".json\", 'w')) as fp:\n",
      "                json.dump(result, fp)\n",
      "code_filename:  {'code': 'def main(folder_path:str, transcriber: object):\\n    \"\"\"\\n    Transcribe a list of files\\n\\n    Args:\\n        folder_path (str): folder path to where the downloaded videos are\\n        transcriber (object): take in the transcriber object\\n    \"\"\"\\n    file_paths = []\\n    for data in os.listdir(folder_path):\\n        data_ob = {\"title\":data[:-4], \"file_location\":os.path.join(folder_path,data)}\\n        file_paths.append(data_ob)\\n\\n    for item in file_paths:\\n        if \".mp3\" in item[\\'file_location\\']: # Basic check for now.\\n            result = transcriber.process_data(item)\\n            with open(os.path.join(folder_path, item[\\'title\\']+\".json\", \\'w\\')) as fp:\\n                json.dump(result, fp)', 'node_type': 'function_definition', 'filepath': './search_app/transcription/main.py'}\n",
      "type:  if_statement\n",
      "bye locations:  776  -  1680\n",
      "code:\n",
      " if __name__ == \"__main__\":\n",
      "    device = \"cpu\"  # \"cuda\"\n",
      "    batch_size = 4 # reduce if low on GPU mem e.g. 16\n",
      "    compute_type = \"int8\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
      "    transcriber = Transcriber(device, batch_size, compute_type)\n",
      "\n",
      "    url_link = input(\"Youtube URL: \") # e.g. \"https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J\"\n",
      "    data_list = get_yt_data(url_link)\n",
      "    print(f\"\\nThere are {len(data_list)} number of videos in the provided link\\n\")\n",
      "    output_path = input(\"Output folder: \")\n",
      "    download_yt_playlist(data_list, output_path)\n",
      "    print(f\"\\nFiles downloaded to {output_path} with {len(os.listdir(output_path))} files.\\n\")\n",
      "\n",
      "    new_data_list = get_yt_thumbnail_link(data_list)\n",
      "    download_yt_thumbnail(new_data_list, output_path)\n",
      "\n",
      "    main(output_path, transcriber)\n",
      "    print(f\"\\nExecution success! Transcriptions are at {output_path}\\n\")\n",
      "code_filename:  {'code': 'if __name__ == \"__main__\":\\n    device = \"cpu\"  # \"cuda\"\\n    batch_size = 4 # reduce if low on GPU mem e.g. 16\\n    compute_type = \"int8\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\\n    transcriber = Transcriber(device, batch_size, compute_type)\\n\\n    url_link = input(\"Youtube URL: \") # e.g. \"https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J\"\\n    data_list = get_yt_data(url_link)\\n    print(f\"\\\\nThere are {len(data_list)} number of videos in the provided link\\\\n\")\\n    output_path = input(\"Output folder: \")\\n    download_yt_playlist(data_list, output_path)\\n    print(f\"\\\\nFiles downloaded to {output_path} with {len(os.listdir(output_path))} files.\\\\n\")\\n\\n    new_data_list = get_yt_thumbnail_link(data_list)\\n    download_yt_thumbnail(new_data_list, output_path)\\n\\n    main(output_path, transcriber)\\n    print(f\"\\\\nExecution success! Transcriptions are at {output_path}\\\\n\")', 'node_type': 'if_statement', 'filepath': './search_app/transcription/main.py'}\n",
      "Total number of functions extracted:  20\n"
     ]
    }
   ],
   "source": [
    "all_nodes = []\n",
    "\n",
    "for code_file in code_files:\n",
    "    nodes = list(get_functions(code_file))\n",
    "    for func in nodes:\n",
    "        all_nodes.append(func)\n",
    "node_count = len(all_nodes)\n",
    "print(\"Total number of functions extracted: \", node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'from yt_dlp import YoutubeDL',\n",
       "  'node_type': 'import_from_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'import pytube',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'from typing import List, Dict',\n",
       "  'node_type': 'import_from_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'import os',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'import re',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'import requests',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'def get_yt_data(url_link:str) -> List[Dict]:\\n  \"\"\"\\n  Given a link, generate the data for each link and yt video\\n\\n  ARGS:\\n    url_link(str): the url link to a video or playlist\\n\\n  Returns:\\n    video_urls(List[Dict]): List of dictionary objects that contain basic metadata on the YT video\\n\\n  \"\"\"\\n  video_urls = []\\n  if \"playlist\" in url_link: # playlists\\n    playlist = pytube.Playlist(url_link)\\n    print(\\'Number Of Videos In playlist: %s\\' % len(playlist.video_urls))\\n    for url in playlist:\\n        data_object = {\"title\":pytube.YouTube(url).title,\\n                      \"description\":pytube.YouTube(url).description,\\n                       \"url\":url}\\n        video_urls.append(data_object)\\n    else:\\n      data_object = {\"title\":pytube.YouTube(url).title,\\n                      \"description\":pytube.YouTube(url).description,\\n                     \"url\":url}\\n      video_urls.append(data_object)\\n  return video_urls',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'def download_yt_playlist(video_urls:list, path:str):\\n  \"\"\"\\n  Download yt videos from list of links\\n\\n  ARGS:\\n    video_urls(list): A list containing a hsot of youtube URL links\\n    path (str): path to save files\\n\\n  \"\"\"\\n  for item in video_urls:\\n    download_yt(item[\"url\"], item[\"title\"], path)\\n    item[\"file_location\"] = os.path.join(path, item[\"title\"]+\".mp3\")',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'def download_yt(url:str, out_fname:str, path:str = \"input\"):\\n  \"\"\"\\n  Download YT videos to a specific location\\n\\n  ARGS:\\n    url(str): A youtube url to a video\\n    out_fname(str): The output file name\\n    path(str): A path to save the file to.\\n  \"\"\"\\n  if not os.path.exists(path):\\n    print(\"Path does not exist\")\\n    return\\n  output = os.path.join(path, out_fname) # example: path == \"input\"\\n  ydl_opts = {\\n      \"format\": \"bestaudio/best\",\\n      \"postprocessors\": [\\n          {\\n              \"key\": \"FFmpegExtractAudio\",\\n              \"preferredcodec\": \"mp3\",\\n              \"preferredquality\": \"192\",\\n          }\\n      ],\\n      \"fragment_retries\": 10,\\n      \"outtmpl\": output,\\n  }\\n  with YoutubeDL(ydl_opts) as ydl:\\n    ydl.download([url])',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'def get_yt_thumbnail_link(url_list:List[Dict]):\\n    \"\"\"\\n    Download the youtube thumbnails as jpg\\n\\n    Args:\\n        url_list (List[Dict[str]]): List of youtube video URLS contained in dictionaries\\n    \"\"\"\\n    pattern = \"watch\\\\?v=(.+)\" # e.g. \\'https://www.youtube.com/watch?v=Z56Jmr9Z34Q\\'-> \\'Z56Jmr9Z34Q\\'\\n    for item in url_list:\\n      url = item[\\'url\\']\\n      matched_pattern = re.search(pattern, url)\\n      if matched_pattern:\\n          content = matched_pattern.group(1)\\n          item[\\'thumbnail\\'] = \"https://i.ytimg.com/vi/\" + content +\"/maxresdefault.jpg\" # location of where yt stores thumbnails\\n    return url_list',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'def download_yt_thumbnail(url_list:List[Dict], path:str):\\n  \"\"\"\\n  Downloads youtube thumbnails to a path\\n\\n  Args:\\n      url_list (List[Dict[str]]): List of youtube data objects\\n      path (str): Path to save youtube thumbnails\\n  \"\"\"\\n  for item in url_list:\\n    img_data = requests.get(item[\\'thumbnail\\']).content\\n    with open(os.path.join(path, item[\\'title\\']+\\'.jpg\\'), \\'wb\\') as handler:\\n        handler.write(img_data)',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/download.py'},\n",
       " {'code': 'import whisperx',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/transcribe.py'},\n",
       " {'code': 'import torch',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/transcribe.py'},\n",
       " {'code': 'class Transcriber():\\n    def __init__(self, device:str = \"cpu\", batch_size:int=4, compute_type:str=\"int8\"):\\n        \"\"\"\\n        Instantiate the class with minimal resources\\n\\n        Args:\\n            device (str, optional): cpu or cuda. Defaults to \"cpu\".\\n            batch_size (int, optional): Bigger number requires more memory. Defaults to 4.\\n            compute_type (str, optional): float16 requires more memory. Defaults to \"int8\".\\n        \"\"\"\\n        self.device = device\\n        self.batch_size = batch_size\\n        self.compute_type = compute_type\\n\\n    def transcribe_file(self, audio_file:str, title:str) -> list:\\n        \"\"\"\\n        Transcripe the files\\n\\n        Args:\\n            audio_file (str): Name of the audio file\\n            title (str): title of the video\\n\\n        Returns:\\n            list: _description_\\n        \"\"\"\\n        device = self.device\\n        compute_type = self.compute_type\\n        batch_size = self.batch_size\\n\\n        # 1. Transcribe with original whisper (batched) with medium.en for speed/accuracy tradeoff\\n        model = whisperx.load_model(\"medium.en\", device, compute_type=compute_type)\\n\\n        audio = whisperx.load_audio(audio_file)\\n        result = model.transcribe(audio, batch_size=batch_size)\\n\\n        # delete model if low on GPU resources\\n        # import gc; gc.collect(); torch.cuda.empty_cache(); del model\\n\\n        # 2. Align whisper output\\n        model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\\n        result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\\n        import gc; gc.collect(); torch.cuda.empty_cache(); del model\\n        counter = 0\\n        for r in result[\"segments\"]:\\n            r[\\'id\\'] = str(counter)+\"_\"+title\\n            r[\\'title\\'] = title\\n            counter +=1\\n\\n        return result\\n\\n    def process_data(self, data:dict)->dict:\\n        \"\"\"\\n        Process the data to a specific output format\\n\\n        Args:\\n            data (dict): Dictionary of transcription results\\n\\n        Returns:\\n            output (dict): Dictionary with new schema\\n        \"\"\"\\n        # Extract the necessary information from the data\\n        title = data[\\'title\\']\\n        url = data[\\'file_location\\']\\n\\n        # Call the transcribe_file function with the video URL\\n        result = self.transcribe_file(url, title)\\n\\n        # Create a dictionary with the desired output format\\n        output = {\\n            \\'title\\': title,\\n            \\'segments\\': result[\"segments\"]\\n        }\\n\\n        return output',\n",
       "  'node_type': 'class_definition',\n",
       "  'filepath': './search_app/transcription/transcribe.py'},\n",
       " {'code': 'import os',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/main.py'},\n",
       " {'code': 'import json',\n",
       "  'node_type': 'import_statement',\n",
       "  'filepath': './search_app/transcription/main.py'},\n",
       " {'code': 'from download import *',\n",
       "  'node_type': 'import_from_statement',\n",
       "  'filepath': './search_app/transcription/main.py'},\n",
       " {'code': 'from transcribe import Transcriber',\n",
       "  'node_type': 'import_from_statement',\n",
       "  'filepath': './search_app/transcription/main.py'},\n",
       " {'code': 'def main(folder_path:str, transcriber: object):\\n    \"\"\"\\n    Transcribe a list of files\\n\\n    Args:\\n        folder_path (str): folder path to where the downloaded videos are\\n        transcriber (object): take in the transcriber object\\n    \"\"\"\\n    file_paths = []\\n    for data in os.listdir(folder_path):\\n        data_ob = {\"title\":data[:-4], \"file_location\":os.path.join(folder_path,data)}\\n        file_paths.append(data_ob)\\n\\n    for item in file_paths:\\n        if \".mp3\" in item[\\'file_location\\']: # Basic check for now.\\n            result = transcriber.process_data(item)\\n            with open(os.path.join(folder_path, item[\\'title\\']+\".json\", \\'w\\')) as fp:\\n                json.dump(result, fp)',\n",
       "  'node_type': 'function_definition',\n",
       "  'filepath': './search_app/transcription/main.py'},\n",
       " {'code': 'if __name__ == \"__main__\":\\n    device = \"cpu\"  # \"cuda\"\\n    batch_size = 4 # reduce if low on GPU mem e.g. 16\\n    compute_type = \"int8\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\\n    transcriber = Transcriber(device, batch_size, compute_type)\\n\\n    url_link = input(\"Youtube URL: \") # e.g. \"https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J\"\\n    data_list = get_yt_data(url_link)\\n    print(f\"\\\\nThere are {len(data_list)} number of videos in the provided link\\\\n\")\\n    output_path = input(\"Output folder: \")\\n    download_yt_playlist(data_list, output_path)\\n    print(f\"\\\\nFiles downloaded to {output_path} with {len(os.listdir(output_path))} files.\\\\n\")\\n\\n    new_data_list = get_yt_thumbnail_link(data_list)\\n    download_yt_thumbnail(new_data_list, output_path)\\n\\n    main(output_path, transcriber)\\n    print(f\"\\\\nExecution success! Transcriptions are at {output_path}\\\\n\")',\n",
       "  'node_type': 'if_statement',\n",
       "  'filepath': './search_app/transcription/main.py'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in all_nodes:\n",
    "    item['code'] = item['code'].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_api = \"http://127.0.0.1:8200/embed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "args = (embedding_api, all_nodes ,headers)\n",
    "\n",
    "def process_item(args:tuple) -> list:\n",
    "    \"\"\"\n",
    "    Vectorise input item's at embedding_api endpoint hosted in docker\n",
    "\n",
    "    Args:\n",
    "        embedding_api (str): URL to endpoint for vectorizer\n",
    "        item (list): List of dictionaries\n",
    "        headers (_type_, optional): _description_. Defaults to headers.\n",
    "        key(str): key to select from the args.item list of dictionaries\n",
    "\n",
    "    Returns:\n",
    "        list: Array containing the vectorized input\n",
    "    \"\"\"\n",
    "    embedding_api, item, headers, key = args\n",
    "    payload = {\"transcription_document\": item[key]}\n",
    "    res = requests.post(embedding_api, json=payload, headers=headers)\n",
    "    item['vector'] = res.json()['vectors']\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes  = mp.cpu_count()\n",
    "num_processes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 'from yt_dlp import YoutubeDL',\n",
       " 'node_type': 'import_from_statement',\n",
       " 'filepath': './search_app/transcription/download.py'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for i in range(len(all_nodes)-1):\n",
    "    args_list = (embedding_api, all_nodes[i], headers, 'code')\n",
    "    result_list.append(process_item(args_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list.append(process_item((embedding_api, all_nodes[-1], headers, 'code'))) # doesn't capture this last one in the for loop for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marqo\n",
    "mq = marqo.Client(url=\"http://localhost:8882\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'my-first-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mq.index(index_name).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"index_defaults\":{\n",
    "        \"model\": \"hf/all_datasets_v4_MiniLM-L6\",\n",
    "        \"normalize_embeddings\":True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'my-first-index'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mq.create_index(index_name, settings_dict = index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': False,\n",
       " 'processingTimeMs': 604.6717500139493,\n",
       " 'index_name': 'my-first-index',\n",
       " 'items': [{'_id': '95dd0172-b32b-4b60-941d-d0dee4d96c75',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'f37ee6cb-35ab-4665-8755-37ecebea0919',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'bcc553e6-aabb-4702-af67-d8d59a7dd1b9',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'ec4be67e-496a-4c45-baf8-9c246201d55a',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '4b12ac3e-82a4-49f8-b4bc-c13d1d5b4921',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'bae1ba57-05b5-4b16-bbb2-1aa06b246add',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'bd071007-5e69-4a8c-b140-89589e2b13fb',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '01fe428f-8d3d-472f-8d21-78cb1f0b4ebb',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'e6f2d116-d1ea-41bf-b297-5ca2510de4a8',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '24316cdf-3ec9-412b-b531-8ccdb64edee7',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'a1b6df5a-d200-4134-af8b-5eacd733fa0b',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '4a7e5185-b3b5-406f-89c9-97a72d870cb1',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'a95d8b2c-a6ed-4d21-947f-d36558f4d360',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '55bdda8f-ab79-43c9-8fb8-828aec0accd7',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'd88d8c2e-bb20-40e6-826c-4f4a4a52a3ac',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '7f73ac5c-9d09-4c47-b138-92a3eaad7b47',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '6187cb14-b77b-467b-84eb-81e4c027360c',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': '5fc29b6d-f78f-4ba5-9f05-8df61b64566a',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'c645dbb3-3a58-4da8-9f2f-96f454b52d7f',\n",
       "   'result': 'created',\n",
       "   'status': 201},\n",
       "  {'_id': 'fe8e0274-da93-4acb-9efe-a76e07196c53',\n",
       "   'result': 'created',\n",
       "   'status': 201}]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mq.index(index_name).add_documents(\n",
    "    all_nodes,\n",
    "    tensor_fields=[\"code\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Given the following extracted parts of code functions (\"FUNCTIONS\") and a question (\"QUESTION\"), create a final answer one paragraph long. Do not try to make up an answer and use the text in the FUNCTIONS only for the answer. If you don't know the answer, just say that you don't know.\n",
    "\n",
    "QUESITON: {question}\n",
    "=========\n",
    "FUNCTIONS:\n",
    "{functions}\n",
    "=========\n",
    "ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template = template, input_variables = [\"question\", \"functions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'my-first-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m mq\u001b[39m.\u001b[39mindex(index_name)\u001b[39m.\u001b[39msearch(question)\n\u001b[1;32m      2\u001b[0m text \u001b[39m=\u001b[39m [res[\u001b[39m'\u001b[39m\u001b[39m_highlights\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results[\u001b[39m'\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m docs \u001b[39m=\u001b[39m [Document(page_content\u001b[39m==\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSource [\u001b[39m\u001b[39m{\u001b[39;00mind\u001b[39m}\u001b[39;00m\u001b[39m]:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mt \u001b[39mfor\u001b[39;00m ind, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(texts))]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "results = mq.index(index_name).search(question)\n",
    "text = [res['_highlights']['text'] for res in results['hits']]\n",
    "docs = [Document(page_content==f\"Source [{ind}]:\"+t for ind, t in enumerate(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrluu/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Where is the transcriber class used?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": \"class Transcriber():     def __init__(self, device:str = \\\"cpu\\\", batch_size:int=4, compute_type:str=\\\"int8\\\"):         \\\"\\\"\\\"         Instantiate the class with minimal resources          Args:             device (str, optional): cpu or cuda. Defaults to \\\"cpu\\\".             batch_size (int, optional): Bigger number requires more memory. Defaults to 4.             compute_type (str, optional): float16 requires more memory. Defaults to \\\"int8\\\".         \\\"\\\"\\\"         self.device = device         self.batch_size = batch_size         self.compute_type = compute_type      def transcribe_file(self, audio_file:str, title:str) -> list:         \\\"\\\"\\\"         Transcripe the files          Args:             audio_file (str): Name of the audio file             title (str): title of the video          Returns:             list: _description_         \\\"\\\"\\\"         device = self.device         compute_type = self.compute_type         batch_size = self.batch_size          # 1. Transcribe with original whisper (batched) with medium.en for speed/accuracy tradeoff         model = whisperx.load_model(\\\"medium.en\\\", device, compute_type=compute_type)          audio = whisperx.load_audio(audio_file)         result = model.transcribe(audio, batch_size=batch_size)          # delete model if low on GPU resources         # import gc; gc.collect(); torch.cuda.empty_cache(); del model          # 2. Align whisper output         model_a, metadata = whisperx.load_align_model(language_code=result[\\\"language\\\"], device=device)         result = whisperx.align(result[\\\"segments\\\"], model_a, metadata, audio, device, return_char_alignments=False)         import gc; gc.collect(); torch.cuda.empty_cache(); del model         counter = 0         for r in result[\\\"segments\\\"]:             r['id'] = str(counter)+\\\"_\\\"+title             r['title'] = title             counter +=1          return result      def process_data(self, data:dict)->dict:         \\\"\\\"\\\"         Process the data to a specific output format          Args:             data (dict): Dictionary of transcription results          Returns:             output (dict): Dictionary with new schema         \\\"\\\"\\\"         # Extract the necessary information from the data         title = data['title']         url = data['file_location']          # Call the transcribe_file function with the video URL         result = self.transcribe_file(url, title)          # Create a dictionary with the desired output format         output = {             'title': title,             'segments': result[\\\"segments\\\"]         }          return output\",\n",
      "    \"node_type\": \"class_definition\",\n",
      "    \"filepath\": \"./search_app/transcription/transcribe.py\",\n",
      "    \"_id\": \"55bdda8f-ab79-43c9-8fb8-828aec0accd7\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"class Transcriber():     def __init__(self, device:str = \\\"cpu\\\", batch_size:int=4, compute_type:str=\\\"int8\\\"):         \\\"\\\"\\\"         Instantiate the class with minimal resources          Args:             device (str, optional): cpu or cuda. Defaults to \\\"cpu\\\".\"\n",
      "    },\n",
      "    \"_score\": 0.72385037\n",
      "}\n",
      "{\n",
      "    \"code\": \"def main(folder_path:str, transcriber: object):     \\\"\\\"\\\"     Transcribe a list of files      Args:         folder_path (str): folder path to where the downloaded videos are         transcriber (object): take in the transcriber object     \\\"\\\"\\\"     file_paths = []     for data in os.listdir(folder_path):         data_ob = {\\\"title\\\":data[:-4], \\\"file_location\\\":os.path.join(folder_path,data)}         file_paths.append(data_ob)      for item in file_paths:         if \\\".mp3\\\" in item['file_location']: # Basic check for now.             result = transcriber.process_data(item)             with open(os.path.join(folder_path, item['title']+\\\".json\\\", 'w')) as fp:                 json.dump(result, fp)\",\n",
      "    \"node_type\": \"function_definition\",\n",
      "    \"filepath\": \"./search_app/transcription/main.py\",\n",
      "    \"_id\": \"c645dbb3-3a58-4da8-9f2f-96f454b52d7f\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"def main(folder_path:str, transcriber: object):     \\\"\\\"\\\"     Transcribe a list of files      Args:         folder_path (str): folder path to where the downloaded videos are         transcriber (object): take in the transcriber object     \\\"\\\"\\\"     file_paths = []     for data in os.listdir(folder_path):         data_ob = {\\\"title\\\":data[:-4], \\\"file_location\\\":os.path.join(folder_path,data)}         file_paths.append(data_ob)      for item in file_paths:         if \\\".mp3\\\" in item['file_location']: # Basic check for now. result = transcriber.process_data(item)             with open(os.path.join(folder_path, item['title']+\\\".json\\\", 'w')) as fp:                 json.dump(result, fp)\"\n",
      "    },\n",
      "    \"_score\": 0.6316288\n",
      "}\n",
      "{\n",
      "    \"code\": \"import re\",\n",
      "    \"node_type\": \"import_statement\",\n",
      "    \"filepath\": \"./search_app/transcription/download.py\",\n",
      "    \"_id\": \"4b12ac3e-82a4-49f8-b4bc-c13d1d5b4921\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"import re\"\n",
      "    },\n",
      "    \"_score\": 0.600995\n",
      "}\n",
      "{\n",
      "    \"code\": \"import torch\",\n",
      "    \"node_type\": \"import_statement\",\n",
      "    \"filepath\": \"./search_app/transcription/transcribe.py\",\n",
      "    \"_id\": \"a95d8b2c-a6ed-4d21-947f-d36558f4d360\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"import torch\"\n",
      "    },\n",
      "    \"_score\": 0.5943059\n",
      "}\n",
      "{\n",
      "    \"code\": \"import whisperx\",\n",
      "    \"node_type\": \"import_statement\",\n",
      "    \"filepath\": \"./search_app/transcription/transcribe.py\",\n",
      "    \"_id\": \"4a7e5185-b3b5-406f-89c9-97a72d870cb1\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"import whisperx\"\n",
      "    },\n",
      "    \"_score\": 0.58967084\n",
      "}\n",
      "{\n",
      "    \"code\": \"if __name__ == \\\"__main__\\\":     device = \\\"cpu\\\"  # \\\"cuda\\\"     batch_size = 4 # reduce if low on GPU mem e.g. 16     compute_type = \\\"int8\\\" # change to \\\"int8\\\" if low on GPU mem (may reduce accuracy)     transcriber = Transcriber(device, batch_size, compute_type)      url_link = input(\\\"Youtube URL: \\\") # e.g. \\\"https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J\\\"     data_list = get_yt_data(url_link)     print(f\\\"\\\\nThere are {len(data_list)} number of videos in the provided link\\\\n\\\")     output_path = input(\\\"Output folder: \\\")     download_yt_playlist(data_list, output_path)     print(f\\\"\\\\nFiles downloaded to {output_path} with {len(os.listdir(output_path))} files.\\\\n\\\")      new_data_list = get_yt_thumbnail_link(data_list)     download_yt_thumbnail(new_data_list, output_path)      main(output_path, transcriber)     print(f\\\"\\\\nExecution success! Transcriptions are at {output_path}\\\\n\\\")\",\n",
      "    \"node_type\": \"if_statement\",\n",
      "    \"filepath\": \"./search_app/transcription/main.py\",\n",
      "    \"_id\": \"fe8e0274-da93-4acb-9efe-a76e07196c53\",\n",
      "    \"_highlights\": {\n",
      "        \"code\": \"if __name__ == \\\"__main__\\\":     device = \\\"cpu\\\"  # \\\"cuda\\\"     batch_size = 4 # reduce if low on GPU mem e.g. 16     compute_type = \\\"int8\\\" # change to \\\"int8\\\" if low on GPU mem (may reduce accuracy)     transcriber = Transcriber(device, batch_size, compute_type)      url_link = input(\\\"Youtube URL: \\\") # e.g.\"\n",
      "    },\n",
      "    \"_score\": 0.56684\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = mq.index(index_name).search(q)\n",
    "results_list = []\n",
    "for item in results['hits']:\n",
    "    if item[\"node_type\"] != \"import_from_statement\":\n",
    "        print(json.dumps(item, indent=4))\n",
    "        results_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Transcriber():     def __init__(self, device:str = \"cpu\", batch_size:int=4, compute_type:str=\"int8\"):         \"\"\"         Instantiate the class with minimal resources          Args:             device (str, optional): cpu or cuda. Defaults to \"cpu\".             batch_size (int, optional): Bigger number requires more memory. Defaults to 4.             compute_type (str, optional): float16 requires more memory. Defaults to \"int8\".         \"\"\"         self.device = device         self.batch_size = batch_size         self.compute_type = compute_type      def transcribe_file(self, audio_file:str, title:str) -> list:         \"\"\"         Transcripe the files          Args:             audio_file (str): Name of the audio file             title (str): title of the video          Returns:             list: _description_         \"\"\"         device = self.device         compute_type = self.compute_type         batch_size = self.batch_size          # 1. Transcribe with original whisper (batched) with medium.en for speed/accuracy tradeoff         model = whisperx.load_model(\"medium.en\", device, compute_type=compute_type)          audio = whisperx.load_audio(audio_file)         result = model.transcribe(audio, batch_size=batch_size)          # delete model if low on GPU resources         # import gc; gc.collect(); torch.cuda.empty_cache(); del model          # 2. Align whisper output         model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)         result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)         import gc; gc.collect(); torch.cuda.empty_cache(); del model         counter = 0         for r in result[\"segments\"]:             r[\\'id\\'] = str(counter)+\"_\"+title             r[\\'title\\'] = title             counter +=1          return result      def process_data(self, data:dict)->dict:         \"\"\"         Process the data to a specific output format          Args:             data (dict): Dictionary of transcription results          Returns:             output (dict): Dictionary with new schema         \"\"\"         # Extract the necessary information from the data         title = data[\\'title\\']         url = data[\\'file_location\\']          # Call the transcribe_file function with the video URL         result = self.transcribe_file(url, title)          # Create a dictionary with the desired output format         output = {             \\'title\\': title,             \\'segments\\': result[\"segments\"]         }          return output'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list[0]['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 951kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.63MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 1.59MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 2.70MB/s]\n"
     ]
    }
   ],
   "source": [
    "highlights, texts = extract_text_from_highlights(results, token_limit=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=f\"Source [{ind}]:\"+t) for ind,t in enumerate(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from transcribe import Transcriber',\n",
       " 'class Transcriber(): def __init__(self, device:str = \"cpu\", batch_size:int=4, compute_type:str=\"int8\"): \"\"\" Instantiate the class with minimal resources Args: device (str, optional): cpu or cuda. Defaults to \"cpu\".',\n",
       " 'def main(folder_path:str, transcriber: object): \"\"\" Transcribe a list of files Args: folder_path (str): folder path to where the downloaded videos are transcriber (object): take in the transcriber object \"\"\" file_paths = [] for data in os.listdir(folder_path): data_ob = {\"title\":data[:-4], \"file_location\":os.path.join(folder_path,data)} file_paths.append(data_ob) for item in file_paths: if \".mp3\" in item[\\'file_location\\']: # Basic check for now. result = transcriber.process_data(item) with open(os.path.join(folder_path, item[\\'title\\']+\".json\", \\'w\\')) as fp: json.dump(result, fp)',\n",
       " 'import re',\n",
       " 'from download import *',\n",
       " 'import torch',\n",
       " 'import whisperx',\n",
       " 'if __name__ == \"__main__\": device = \"cpu\" # \"cuda\" batch_size = 4 # reduce if low on GPU mem e.g. 16 compute_type = \"int8\" # change to \"int8\" if low on GPU mem (may reduce accuracy) transcriber = Transcriber(device, batch_size, compute_type) url_link = input(\"Youtube URL: \") # e.g.',\n",
       " 'from yt_dlp import YoutubeDL',\n",
       " 'from typing import List, Dict']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m final_answer \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m     messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mHello\u001b[39;49m\u001b[39m\"\u001b[39;49m}],\n\u001b[1;32m      4\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/repo_search/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
